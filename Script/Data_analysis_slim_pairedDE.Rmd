---
title: "MS Data Analysis Workflow"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    code_folding: hide
    self_contained: true
    lightbox: true
    gallery: true
---

```{r, warning =FALSE, echo = FALSE, message = FALSE}
library(devtools) #for install run: install.packages("devtools")
library(diann) #for install run: install_github("https://github.com/vdemichev/diann-rpackage")
library(tidyverse) #for install run: install.packages("tidyverse")
library(magrittr) #for install run: install.packages("magrittr")
library(limma) #for install run: BiocManager::install("limma")
library(ggpubr) #for install run: install.packages("ggpubr")
library(proDA) #for install run: BiocManager::install("proDA")
library(sjmisc) #for install run: install.packages("sjmisc")
library(ggalt) #for install run: install.packages("ggalt")
library(ggrepel) #for install run: install.packages("ggrepel")
library(DT) #for install run: install.packages("DT")
library(arrow) #for install run: install.packages("arrow")
library(missForest) #for install run: install.packages("missForest")
library(clusterProfiler) #for install run: BiocManager::install("clusterProfiler")

#general settings
knitr::opts_chunk$set(echo = FALSE) #omits code when knitting to html document
set.seed(1337) #this makes results (e.g imputation) reproducible

```

This script will handle the processing of a DIA-NN output file, transform the search engine output to a unique *protein quantity matrix*, perform basic *preprocessing* to make the data ready for further analysis.
Furthermore, it includes basic principle component analysis *(PCA)* clustering, **paired** differential expression analysis and Gene Set Enrichment Analysis *(GSEA)*.

**Example Data:**
The example data used in this script are diaPASEF data acquired with a timsTOF Flex HT from two pancreatic cancer cell lines (BxPC3 and PanC1) with 8 replicates each. The data were acquired on an EvoSep One LC system using a 90 SPD method. The DIA-NN output was generated using DIA-NN version 2.0 with a spectral library generated from the same data using DIA-NN's library-free search option. For improved runtimes and to reduce file size, the output file was subsetted to 250.000 rows, instead of >950.000 rows (Option A in chunk below). *However*, full dataset can be downloaded separately if needed, instructions in code below (Option B in chunk below).

# Processing DIA-NN Output

The DIA-NN raw output was processed using the corresponding R-package. A unique protein (proteotypic peptides only) output was generated utilizing MaxLFQ intensities and applying a 1% FDR cutoff for both peptides and proteins. Proteins identified by just one peptide were removed from the dataset.

```{r, warning = FALSE, message = FALSE}
########################################################
##load the diann output and calculate protein quantities
########################################################
#load the diann output (this can be very large and therefore can take some time)
#Option A: subsetted dataset for improved runtimes, included in repo
df <- read_parquet("./InputData/Example_Raw_Data/MassSpec_diaPASEF_90SPD_BxPC3_Panc1_sub.parquet") ####!!!!ADJUSTMENT NEEDED FOR OWN DATA: define filepath!!!!!

#Option B: Full dataset (105 mb, from Nextcloud, increased runtimes)
#download file from Nextcloud by uncommenting the following code. The file willd be downloaded to the defined filepath and loaded as df. Make sure to adjust the filepath to your needs. The code checks if the file already exists, and if not, it will download it. This is to avoid downloading the file multiple times if you run the script multiple times.
#data_file <- "./InputData/Example_Raw_Data/MassSpec_diaPASEF_90SP_#BxPC3_Panc1_full.parquet"
#if (!file.exists(data_file) && grepl("full", data_file, fixed = #TRUE)) {
#  full_url <- "https://cloud.oxygin.net/public.php/dav/files/QCCX##PLWHbQNzKj/?accept=zip"
#  cat("Downloading full dataset (~105 MB)...\n")
#  download.file(full_url, data_file, mode = "wb", quiet = FALSE)
#  }
#df <- read_parquet(data_file)

##get unique proteins from output by using proteotypic peptides
unique.proteins <- diann_maxlfq(df[df$Lib.Q.Value <= 0.01 & df$Lib.PG.Q.Value <= 0.01 & df$Proteotypic >= 1,], group.header="Genes", id.header = "Genes.MaxLFQ.Unique", sample.header = "Run") #we apply a FDR cutoff of 1% for both peptides and proteins, and require that the peptides used for quantification are proteotypic
unique.proteins %<>% as.data.frame() %>% rownames_to_column(var = "Genes") #transform the datamatrix to a dataframe for easy handling with tidyverse functions

########################################################
##remove proteins identified by just one peptide
########################################################
#remove proteins identified by just one peptide: for this, first extract the proteins that were identified by just one peptide 
##first extract unique peptides with applied FDR criteria
pep <- unique(df[df$Lib.Q.Value <= 0.01 & df$Lib.PG.Q.Value <= 0.01 & df$Proteotypic >= 1, c('Stripped.Sequence', 'Genes')])

##then count peptides per protein and filter for those with exaclty one peptide
single_peps <- pep %>% 
  count(Genes) %>%
  filter(n == 1) %>%
  select(Genes)

#filter out proteins identified by just one peptide
unique.filtered <- unique.proteins %>% filter(!Genes %in% single_peps$Genes) #filter out proteins identified by just one peptide

########################################################
##adjust sample names for easy usage
########################################################
#sample names (column names of unique.filtered) are the full file paths of the corresponding raw files, and the sample names are typically burried inside. We extract the sample names and use them as column names
## For this, we have many options, but splitting the file path by common prefixes and suffixes is a robust way to extract the sample names

### !!! However, this might need ADJUSTMENT, as it is not guaranteed that your file paths prefixes and suffixes match the ones used here!!!
# 1.we extract the sample names and store them in a vector
# 2. we use str_split_i to split the file paths by common prefixes: the string between "" is the common prefix that is removed from the file paths, i =2 means that everything after the prefix is kept
# 3. S1 or S2 is the rack position on the EVOSEP, which always follow the sample name. We remove this information by splitting the string at the position of S1 or S2 and keeping everything before that
sample.names <- unique.filtered %>% dplyr::select(-Genes) %>% colnames() #get names
sample.names %<>% str_split_i("TCIPA_", i = 2) #split by common prefix
sample.names %<>% str_split_i("_S1|_S2|_S3|_S4|_S5|_S6", i = 1) #split by common suffix

##create new df using unique.filtered and add new samples names
data <- unique.filtered
colnames(data) <- c("Genes", sample.names) #rename columns

#for later steps we need the sample to group/condition mapping which should be stored in a meta file
####!!!!ADJUSTMENT NEEDED: define filepath!!!!!
meta <- read.csv("./InputData/Example_Meta_Data/Example_meta.csv", header = TRUE, sep = ",") #load the mapping file


#remove all unnecessary object to keep Environment clean
rm(list=ls()[! ls() %in% c("data", "meta")]) 
```


```{r}
########################################################
##QC: Check for low ID samples
########################################################
#This step will check, whether some columns are low in protein IDs and maybe should be removed.
##If samples are below the specified threshold (e.g. 50%) IDs, a warning will be displayed below this code-chunk.

check_valids <- function(data, meta, threshold = .5) {
  n_rows <- nrow(data)
  sample_cols <- setdiff(colnames(data), "Genes")
  
  # Absolute protein counts per sample (no ratios in plot)
  valid_summary <- data %>%
    summarise(across(all_of(sample_cols), ~ sum(!is.na(.x)))) %>%
    pivot_longer(everything(), names_to = "samples", values_to = "n_proteins") %>%
    left_join(meta, by = "samples") %>%
    mutate(
      valid_ratio = n_proteins / n_rows,  # For threshold only
      below_threshold = valid_ratio < threshold
    ) %>%
    arrange(desc(n_proteins))
  
  # Warning
  low_ids <- valid_summary %>%
    filter(below_threshold) %>%
    pull(samples)
  
  if (length(low_ids) > 0){
    warning("WARNING: Samples with <", threshold*100, "% proteins: ", 
            paste(low_ids, collapse = ", "))
  }
  
  # Plot: ABSOLUTE protein counts, condition-colored
  p <- valid_summary %>%
    ggplot(aes(x = reorder(samples, n_proteins), y = n_proteins, 
               fill = condition, alpha = below_threshold)) +
    geom_col(width = 0.8) +
    geom_hline(yintercept = threshold * n_rows, linetype = "dashed", 
               color = "firebrick", linewidth = 1, alpha = 1) +
    coord_flip() +
    scale_alpha_manual(values = c("FALSE" = 1, "TRUE" = 0.7), guide = "none") +
    labs(
      title = "Proteins Identified per Sample from Raw Data",
      subtitle = paste("Red line:", round(threshold * n_rows), "proteins (", 
                      threshold*100, "% of", n_rows, "total)"),
      x = "Sample", y = "Proteins Identified",
      caption = paste("Low-ID samples:", sum(valid_summary$below_threshold))
    ) +
    theme(axis.text.y = element_text(size = 9))
  
  print(p)  # Force display in Rmd
  
  return(valid_summary)
}

qc_res <- check_valids(data, meta) #run the function


## In case of a warning and if some samples should be removed, uncomment (remove "#") the following code and specify the columns that should be removed by their column name.

# samples2kick <- qc_res %>% filter(below_threshold) %>% pull(samples)
# data <- data %>% dplyr::select(Genes, all_of(setdiff(colnames(data), samples2kick)))
# meta <- meta %>% filter(!samples %in% samples2kick)
# cat("Removed", length(samples2kick), "samples: ", paste(samples2kick, collapse = ", "))

## NOTE: In these training/example data, one sample is flagged as low-ID. However, this is due to reducing the size of the training dataset. You can decide wheter to keep it or not. In the full dataset, the sample is not flagged as low-ID, as it contains more proteins.

#remove all unnecessary object to keep Environment clean
rm(list=ls()[! ls() %in% c("data", "meta", "qc_res")])
```

The prepared dataset contains MaxLFQ intensities for **`r nrow(data)`** proteins and **`r ncol(data)-1`** samples.

# Pre-processing
In this section, we will perform basic preprocessing on the data, which includes filtering for completeness, normalization and imputation of remaining missing values.

* Filtering: We applied a condition-based filtering, meaning that a protein has to be identified in at least 80% of the samples in at least one group to be retained for further analysis. This ensures that proteins that are only identified in one group but not in the other are retained for further analysis. Making the filtering group size dependent ensures identical stringency for groups of different sizes.

* Normalization: We applied median normalization to the data.

* Imputation: **Random forest-based** imputation was performed using the missForest R package. Missing values were imputed using the missForest function with default parameters. 


```{r, warning = FALSE}
########################################################
##Filtering for completeness
########################################################

## We will apply a condition filter: A protein has to be identified in a certain fraction of samples per group to be included.
# Define filter threshold (e.g., 0.8 for 80%)
filter_threshold <- 0.8 #threshold of group completeness to reach for a protein to be kept, could be adjusted depending on desired stringency

# Pivot data longer for easier joining with meta
long_data <- data %>%
  pivot_longer(cols = -Genes, names_to = "samples", values_to = "intensity")

# Join with group meta info to bring in the condition/group information
long_data <- long_data %>%
  left_join(meta, by = "samples")

# Flag non-missing quantification
long_data <- long_data %>%
  mutate(present = !is.na(intensity))

# Summarize within each protein/group combination
group_summary <- long_data %>%
  group_by(Genes, condition) %>%
  summarise(
    n_present = sum(present),
    n_total = n(),
    prop_present = n_present / n_total,
    .groups = "drop"
  )

# Only keep proteins present in >= filter_threshold of samples in any group
proteins_to_keep <- group_summary %>%
  filter(prop_present >= filter_threshold) %>%
  pull(Genes) %>%
  unique()

# Filter the original data
filtered_data <- data %>% dplyr::filter(Genes %in% proteins_to_keep) #filter the data to only include proteins that are in the proteins_to_keep vector
data <- filtered_data #set data to filtered data

########################################################
##Normalization
########################################################
#We will apply median Normalization on the data
data %<>% 
      column_to_rownames(var = "Genes") %>% #the normalization function expects a matrix with rownames, so we use genes as rownames
        as.matrix() %>% #transform to matrix object
         log(base = 2) %>% #log2 transformation
           proDA::median_normalization() %>% #perform the normalization
            as.data.frame() %>% #transform back to dataframe
              rownames_to_column(var = "Genes") #add genes as column instead of rownames


########################################################
##Imputation
########################################################

#missForest is used for random forest based imputation
data_imputed <- data %>% rotate_df(cn = TRUE) %>% as.matrix() %>%
missForest()

data <- data_imputed[["ximp"]] %>% as.data.frame() %>% sjmisc::rotate_df(cn = FALSE) %>% rownames_to_column(var = "Genes") #transform back to dataframe

write.csv(data, file = "./OutputData/Processed_Data.csv", row.names = FALSE) #write processed data to file

DT::datatable(data, extensions = 'Buttons',
                      caption = "Pre-processed proteomics data.",
                      options = list(dom = 'Blfrtip',
                                     buttons = c('copy', 'csv', 'excel')
                      ))


rm(list=ls()[! ls() %in% c("data", "meta")])
```



# Clustering
In this section, we will perform a basic principle component analysis (PCA) to visualize the data structure. The PCA will be performed on the processed data.
Each point in the plot resembles a sample.

PCA (principal component analysis) is a technique used to reduce the dimensionality of high-dimensional data by projecting it onto a lower-dimensional space. In other words, PCA helps to identify the most important features (or "components") of a dataset, and then create a new set of variables that capture most of the variation in the data. PCA clustering, therefore, is the process of using PCA to cluster data points based on their similarity in the reduced feature space. The PCA algorithm works by finding a linear transformation that maps the original data onto a new coordinate system where the first principal component (PC), captures the direction of maximum variance, the second PC captures the direction of the second-highest variance, and so on. Once the PCs are identified, the data can be projected onto the PC space, usually with PC1 on the X-, and PC2 on the Y-axis.

```{r}
########################################################
##Data preparation
########################################################

##The PCA function requires the data with samples in rows and features in columns, so first we transpose the data. Furthermore, it requires rownames.
data_t <- data %>% rotate_df(cn = 1)

#compute the Principal components
PC <- prcomp(data_t, center = TRUE, scale = FALSE) #perform PCA
PCA_df <- as.data.frame(PC$x) #transform the PCA results to a dataframe
PCA_df %<>% rownames_to_column(var = "samples") %>% dplyr::select(samples, PC1, PC2) #add sample names as column and keep only the first two PCs

#calculate the percentage of explained variance by each PC. This is important for the Axis labels
explained_variance <- PC$sdev^2 / sum(PC$sdev^2) * 100 #calculate the explained variance
pc1_variance <- round(explained_variance[1], 2) #extract for PC1
pc2_variance <- round(explained_variance[2], 2) #extract for PC2

#merge the PCA results with the metadata
PCA_df <- merge(PCA_df, meta, by = "samples")

########################################################
##Plot preparation
########################################################

PCA_df %>%
  ggplot(aes(x = PC1, y = PC2, col = condition, fill = condition)) + #define the plots aesthetics
  geom_encircle(expand = 0, alpha = .5, s_shape = 1, size = 1.5, spread = 0.0001) + #this function is used to enframe samples of the same category
  geom_point(size = 2) + #add the geom_point to create a scatter plot
  ggtitle("PCA Plot", subtitle = str_c("Input proteins: ", nrow(data))) + #add title and subtitle
  labs(x = sprintf("PC1 (%s%% variance)", pc1_variance), ## add variance explained as axis labels 
       y = sprintf("PC2 (%s%% variance)", pc2_variance)) +
  geom_text_repel(aes(label = replicate), box.padding = 0.5, point.padding = 0.5, col = "grey33", size = 3) #add replicates to the plot, if desired.


rm(list=ls()[! ls() %in% c("data", "meta")]) 
```



# Differential Expression Analysis for paired setups

The R package [Limma](https://academic.oup.com/nar/article/43/7/e47/2414268) (linear models for Microarray and RNA-Seq Data) was initially written for differential expression analysis for RNA-sequencing and microarray data. However, the underlying principles and especially the code is also useful for proteomics data.

limma is a *moderated* statistical test, which means that it adjusts the estimates of the test statistic to account for the degree of variability in the data. The purpose of moderation is to improve the accuracy and stability of the estimates, particularly in cases where the sample size is small or the data are noisy.

To test for differential expression, limma fits the GLM to the data and then uses empirical Bayes method for stabilizing the estimates of the coefficients in the limma model. The rationale behind using the empirical Bayes method stems from the fact that the *sample variance* is not an efficient statistic, which means that it takes a certain number of observations before the sample variance converges towards the true underlying variance that we are trying to estimate. In many omics experiments, we have far fewer observations than necessary to get a good estimate of the variance. The empirical Bayes method aims to improve the precision of this estimate. This is done by calculating an *expected variance* that has a higher probability of being representative of the true underlying variance, and then adjust the observed variance towards the expected variance. In simple terms, first an average variance, based on all genes/proteins in the matrix, is calculated (which will be more accurate as it is based on much more data), then for each gene/protein a sample variance is computed which is in turn adjusted towards the expected variance.

This script will perform a differential expression analysis for a **paired setup**. This means that the samples are paired, and the analysis will test for differences between the paired samples, which will increase the statistical power of the test.


```{r, warning = FALSE}
########################################################
##Data preparation
########################################################
#for easy mapping, we ensure the that the order of samples in 'data' is the same as in the 'meta' object. This may already be the case, but this will ensure the order, which is very important.
data.lm <- data %>% dplyr::select(Genes, str_c(meta$condition, "_", meta$replicate))

#limma requires a data matrix as input, so we create a matrix object from data.lm
mat <- data.lm %>% column_to_rownames(var = "Genes") %>% as.matrix()


#pairing information needs to be included within the design matrix using factors
#!!NOTE that the pairing for the example date is entirely made up, and only serves as an example for the code. We use the replicate variable as dummy pairing information. In a real experiment, the pairing information should be based on the experimental setup!!

#build the factors with information on pairs and group
pairs <- factor(meta$replicate) #this is the pairing information
group <- factor(meta$condition, levels = c("PanC1", "BxPC3")) #this is the group information, mention each group in in the levels argument

#we need to create a design matrix for limma. The design matrix is a matrix that describes the experimental design of the experiment. It is used to model the relationship between the samples and the conditions and in this case, pairs.
design <- model.matrix(~pairs+group) #create the design matrix


########################################################
##Fit the model
########################################################

#We now use this design matrix along with the expression data stored in mat to fit the linear model required for DEA
fit <- lmFit(mat, design)

#apply empirical Bayesian method on the fit object
efit <- eBayes(fit, trend = TRUE, robust = TRUE)

#extract contrast/coefficient name from design matrix (last column)
contrast <- design %>% colnames() %>% tail(1) %>% as.character()

#extract the unfiltered limma results as dataframe, thereby applying Benjamini-Hochberg correction for multiple testing
df.limma <- topTable(efit, coef = contrast, adjust = "BH", sort.by = "P", number = Inf, p.value = 1, lfc = NULL) %>% rownames_to_column(var = "Gene.Symbol")


## include the results table as interactive table
df.limma %>% format(df.limma$P.Value, scientific = TRUE) %>% format(df.limma$adj.P.Val, scientific = TRUE) %>%
DT::datatable(extensions = 'Buttons',
                options = list("dom" = 'Blfrtip',
                               buttons = c('copy', 'csv', 'excel')),
                caption = "Differential expression analysis results")

```


```{r}
#In this code chunk, we create some plotting parameters that will the creation of comparable plots easier

## These values will define the classification of proteins as significant or not and will be used as cutoff for threshold lines in the volcano plots
pos_FC <- 1 #positive log2FC threshold
neg_FC <- -1 #negative log2FC threshold
pcut <- 0.05 #p-value of posthoc threshold
p.GSEA <- 0.05 #p-value threshold for GSEA results

```

<!--
!!!!!!!! ADJUSTMENT NEEDED: Copy the section below for as many contrasts as you have in your analysis. Make sure to adjust the contrast name in the code chunk below and in the subsequent sections. The contrast name has to match the contrast names defined in the contrast matrix. !!!!!!!! 
-->

## BxPC3 vs PanC1

### Differential Expression {.tabset .tabset-fade .tabset-pills}

#### Volcano Plot

```{r, echo = FALSE, warning = FALSE}
########################################################
##Data preparation
########################################################
#This will create all the data needed for the volcano plot

#this will get the group labels in the plot right
groups <- levels(group)
group1 <- groups[2] #this defines group 1, for up/down regulation annotation
group2 <- groups[1] #this defines group 2, for up/down regulation annotation
title <- str_c(group1, " vs. ", group2) #This will create a title string for the plot

#add a column that indicates the differential expression
df.limma %<>%  mutate(diffexpressed = case_when(logFC >= pos_FC&adj.P.Val <= pcut ~ 'Up', logFC <= neg_FC&adj.P.Val <= pcut ~ 'Down', logFC <= pos_FC | logFC >= neg_FC ~ 'NotSig'))

#create DF with significant proteins only
sig <- df.limma %>% filter(diffexpressed != "NotSig") #This is important for the generation of labels

##generate labels for the volcano plot
up <- "Up in"
down <- "Down in"
uplabel <- str_c(up, group1, sep = " ") 
downlabel <- str_c(down, group1, sep = " ")
subtitle <- str_c(nrow(sig), " differentially expressed proteins.")
caption <- str_c(length(levels(pairs)), " vs. ", length(levels(pairs)), " samples") #caption for the plot, specifying the group sizes

##automated positioning of text labels regarding up/down regulation in the volcano plot
side_decision <- if(abs(max(df.limma$logFC, na.rm = TRUE)) < abs(min(df.limma$logFC, na.rm = TRUE))) "right" else "left" #the side with the smaller absolute logFC decides the x- positioning of the text labels
label_value <- if(side_decision == "right") max(df.limma$logFC, na.rm = TRUE) else min(df.limma$logFC, na.rm = TRUE) #the value of the logFC that decides the x- positioning of the text labels
label_value <- label_value/2 #this will position the text labels at 1/2 of the plot width of the shorter x-saxis side
text_x <- abs(label_value)
text_negx <- -abs(label_value)

########################################################
##Plot preparation
########################################################
#First create an ggplot object with the basic aesthetics
plot <- df.limma %>%
  ggplot(mapping = aes(x=logFC, y=-log10(adj.P.Val), color=diffexpressed, alpha = diffexpressed)) +
  geom_point() +
  scale_alpha_manual(guide = 'none', values = c(Down = 1, Up = 1, NotSig = .4)) + #This regulates the density of the points. The higher the value, the more dense the color
  geom_vline(xintercept=c(neg_FC, pos_FC), col="black", linetype="dashed") + #add vertical lines for log2FC thresholds
  geom_hline(yintercept=-log10(pcut), col="black", linetype="dashed") + #add horizontal line for p-value threshold
  scale_color_manual(breaks = c("Down", "NotSig", "Up"), values = c("#440F76FF", "grey56", "#ED5A5FFF"))+ #color the points, depending on the differential expression
  ylab(bquote(~-log[10]~"q-value limma")) + #add y-axis label 
  #ylim(0, y_limmax)+ #set y-axis limits
  xlab(bquote(~log[2]~"Fold Change")) + #add x-axis label
  #xlim(x_lim_neg, x_lim_pos) + #set x-axis limits
  labs(title = title, subtitle = subtitle, caption = caption
  ) + #add title and subtitle
  theme(legend.position="bottom") + #fix legend at bottom of the plot
  annotate("text", x=text_x, y=0, label = uplabel, col = "grey56")+ #add annotation for upregulation
  annotate("text", x=text_negx, y=0, label = downlabel, col = "grey56") #add annotation for downregulation
plot + geom_text_repel(
  data = sig,
  aes(label = Gene.Symbol),
  color = "grey28",
  size = 2.5
)

```

#### DE Table

```{r, echo = FALSE, warning = FALSE}
#This table will show the significant proteins only
sig %<>% mutate(Euclid.dist = sqrt((logFC^2 + log(adj.P.Val, 10)^2)), .after = logFC) %>% arrange(desc(Euclid.dist))

sig %>% #format(sig$P.Value, scientific = TRUE) %>% format(sig$P.value.adj, scientific = TRUE) %>%
DT::datatable(extensions = 'Buttons',
                options = list("dom" = 'Blfrtip',
                               buttons = c('copy', 'csv', 'excel')),
                caption = 'Significant Proteins') %>%
  DT::formatRound(columns = c("logFC", "t", "Euclid.dist"), digits = 3)

```


# GSEA 

<details>
  <summary>**Click here for GSEA background information**:</summary>

Gene set enrichment analysis (GSEA) is a computational method used to analyze gene expression data to identify sets of genes or pathways that are differentially expressed between two or more groups of samples. In simple terms, GSEA works by comparing the expression of a predefined set of genes (called gene set) between groups of samples, such as healthy vs. diseased tissue. The gene set can represent a variety of biological functions, such as metabolic pathways, a signaling pathway, or a set of genes with a common function.
GSEA assigns a score to each gene set based on the degree to which its members are overrepresented at the top or bottom of a ranked list of genes, which is typically ordered by the magnitude of the difference in expression between the two groups (here, we use the log fold change derived from differential expression analysis carried out before). If the genes in a gene set are mostly overrepresented at the top of the ranked list, this indicates that they are more highly expressed in one group compared to the other.
The statistical significance of the scores is assessed by permuting the samples labels to generate a null distribution and calculating the false discovery rate (FDR) to control for multiple testing.

It should be noted, that GSEA substantially differs from simple overrrepresentation analysis (*ORA*), which is also used to identify enriched gene sets in omics data. ORA is a statistical method that determines whether a gene set is overrepresented in a given dataset compared to what would be expected by chance. ORA typically uses statistical test or hypergeometric test to determine whether the number of genes in a gene set that are differentially expressed is significantly greater than would be expected by chance. Therefore, GSEA does not require pre-defined thresholds for determining differential expression, but instead, ranks all genes in a dataset based on their degree of their differential expression. GSEA assesses the enrichment of each gene set by calculating a running sum statistic that measures the degree of overrepresentation of the gene set in the ranked list of genes.The statistical significance of the running sum statistic is then evaluated using a permutation test. Another key difference between GSEA and ORA is that GSEA takes into account the entire distribution of gene expression changes rather than just the subset of genes that pass a significance threshold in the differential expression analysis. This approach can be more sensitive  to subtle changes in gene expression and can identify gene sets that would be missed by ORA.

P-Values are corrected using the *Benjamini-Hochberg* method, significance is considered if **p-adj.(FDR) < `r p.GSEA`**.

The analyses is carried with the R package 'clusterProfiler' [Yu, Wang, & He, 2012](https://www.liebertpub.com/doi/10.1089/omi.2011.0118) & [Wu, 2021](https://www.sciencedirect.com/science/article/pii/S2666675821000667?via%3Dihub). 

Further reading:

  * [Subramanian et al., 2005](https://pubmed.ncbi.nlm.nih.gov/16199517/)
  * [Kathri, Sirota & Butte, 2012](https://pubmed.ncbi.nlm.nih.gov/22383865/)
  * [Tarca et al. 2009](https://pubmed.ncbi.nlm.nih.gov/18990722/)
  * [Huang, Sherman & Lempicki, 2009](https://pubmed.ncbi.nlm.nih.gov/19131956/)
  
</details>


**Disclaimer:** The GSEA suffers from the reduced dataset size described in the beginning. The unspecific filtering really dismantles the biological information in the data, which is why the GSEA results are not very meaningful. However, the code is provided for demonstration purposes and can be applied to the full dataset without any adjustments.

```{r echo = FALSE}
## data prep ##
res = df.limma

# define the organism of the dataset
#For GO analyses:
#organism_GO = "org.Dm.eg.db" #drosophila melanogaster
organism_GO = "org.Hs.eg.db" #Homo Sapiens
#organism_GO = "org.Mm.eg.db" #Mus Musculus
#More organisms available at: http://bioconductor.org/packages/release/BiocViews.html#___OrgDb

#extract fold changes
orig_gene_list <- res$logFC
#name the vector
names(orig_gene_list) <- res$Gene.Symbol
#omit NAs
gene_list <- na.omit(orig_gene_list)
#sort decreasing order (prerequisite for clusterProfiler)
gene_list = sort(gene_list, decreasing = TRUE)

#generate labels for enrichment direction

act_lab <- stringr::str_c("enriched in ", group1)
sup_lab <- stringr::str_c("enriched in ", group2)

```

## Gene ontology {.tabset .tabset-fade .tabset-pills}

### GO.BP
[Gene Ontology Consortium](http://geneontology.org/) knowledgebase is the world’s largest source of information on the functions of genes. Here the larger processes, or ‘biological programs’ accomplished by multiple molecular activities are assessed.

However, there a more subontologies available, which can be used for GSEA as well. These include: 'molecular function' & 'cellular component'.

```{r echo = FALSE, fig.height = 7, fig.width = 12, eval = TRUE, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}

#GO term Biological Process
gseBP <- gseGO(geneList = gene_list, #gene_list contains genes and their log2FC values, which are used for ranking the genes in GSEA
             ont = "BP", #specifies that the biological process ontology should be used for the analysis
             keyType = "SYMBOL", #Gene symbols as input
             pvalueCutoff = p.GSEA, #p-value threshold for significant enrichment
             pAdjustMethod = "BH", #Benjamini-Hochberg correction for multiple testing
             verbose = FALSE, #omit message printing
             seed = TRUE, #consider random seed for reproducibility
             OrgDb = organism_GO, #specifies the organism
             eps = 1e-20) #a small number to prevent underflow when calculating p-values

df.BP <- gseBP@result #extract results as data.frame
rownames(df.BP) <- c() #remove rownames

#generate a dataframe with top 10 positive and negative enrichments, selected by normalized enrichment score (NES)
topBP <- full_join((df.BP %>% filter(NES >= 0) %>%
                      slice_max(order_by = NES, n = 10)), (df.BP %>% filter(NES <= 0) %>% slice_min(order_by = NES, n = 10)))

#generate a lollipop style plot
ggplot(topBP, aes(x = reorder(Description, NES), y = NES, color = p.adjust)) + #define the plot aesthetics, reorder the x-axis by NES and color by adjusted p-value
  geom_segment(aes(xend=Description, y=0, yend=NES), color = "grey", size = 2) + #add segments from y=0 to the NES value for each term, colored grey
  geom_point(size = 4) + #add points at the end of the segments, size 4
  coord_flip() + #flip the coordinates to make it horizontal
  scale_x_discrete(labels=function(x) str_wrap(x, width=60)) + #wrap long x-axis labels to a width of 60 characters
  theme(strip.text.x = element_text(size = 8)) + #adjust the size of the facet labels
  labs(x = "", y = "Normalized enrichemnt score (NES)", subtitle = "Top 10 positive and negative enrichments selected by normalized enrichment score", title = "GO:Biological Process") + #add axis labels and title
  annotate("text", nrow(topBP)+.4, y = max(topBP$NES)/3, label = act_lab, col = "grey10", size = 3, family = "IBMPlexSans") + #add annotation for the positive enrichment direction
  annotate("text", nrow(topBP)+.4, y = min(topBP$NES)/3, label = sup_lab, col = "grey10", size = 3, family = "IBMPlexSans") #add annotation for the negative enrichment direction
```


```{r, echo = FALSE, eval = TRUE, error = TRUE}
DT::datatable(df.BP %>% dplyr::select(-leading_edge, -core_enrichment), extensions = 'Buttons',
                options = list(order = list(list(7 , 'asc')),
                               "dom" = 'Blfrtip',
                               buttons = c('copy', 'csv', 'excel')),
                caption = 'Significant Proteins') %>%
    DT::formatRound("enrichmentScore", digits=3) %>%
    DT::formatRound("NES", digits=3) %>%
    DT::formatSignif("pvalue", digits=5) %>%
    DT::formatSignif("p.adjust", digits=5) %>%
    DT::formatSignif("qvalue", digits=5)

```


### GO.MF
[Gene Ontology Consortium](http://geneontology.org/) knowledgebase is the world’s largest source of information on the functions of genes. Here the molecular level activities performed by gene products are assessed.

```{r, echo = FALSE, fig.height = 7, fig.width = 12, message = FALSE, warning = FALSE, error = TRUE, eval = TRUE}

#GO term Molecular Function
gseMF <- gseGO(geneList = gene_list, #gene_list contains genes and their log2FC values, which are used for ranking the genes in GSEA
             ont = "MF", #specifies that the molecular function ontology should be used for the analysis
             keyType = "SYMBOL", #Gene symbols as input
             pvalueCutoff = p.GSEA, #p-value threshold for significant enrichment
             pAdjustMethod = "BH", #Benjamini-Hochberg correction for multiple testing
             verbose = FALSE, #omit message printing
             seed = TRUE, #consider random seed for reproducibility
             OrgDb = organism_GO, #specifies the organism
             eps = 1e-20) #a small number to prevent underflow when calculating p-values

df.MF <- gseMF@result #extract results as data.frame
rownames(df.MF) <- c() #remove rownames

#generate a dataframe with top 10 positive and negative enrichments, selected by normalized enrichment score (NES)
topMF <- full_join((df.MF %>% filter(NES >= 0) %>%
                      slice_max(order_by = NES, n = 10)), (df.MF %>% filter(NES <= 0) %>% slice_min(order_by = NES, n = 10)))

#generate a lollipop style plot
ggplot(topMF, aes(x = reorder(Description, NES), y = NES, color = p.adjust)) + #define the plot aesthetics, reorder the x-axis by NES and color by adjusted p-value
  geom_segment(aes(xend=Description, y=0, yend=NES), color = "grey", size = 2) + #add segments from y=0 to the NES value for each term, colored grey
  geom_point(size = 4) + #add points at the end of the segments, size 4
  coord_flip() + #flip the coordinates to make it horizontal
  scale_x_discrete(labels=function(x) str_wrap(x, width=60)) + #wrap long x-axis labels to a width of 60 characters
  theme(strip.text.x = element_text(size = 8)) + #adjust the size of the facet labels
  labs(x = "", y = "Normalized enrichemnt score (NES)", subtitle = "Top 10 positive and negative enrichments selected by normalized enrichment score", title = "GO:Molecular Function") + #add axis labels and title
  annotate("text", nrow(topMF)+.4, y = max(topMF$NES)/3, label = act_lab, col = "grey10", size = 3, family = "IBMPlexSans") + #add annotation for the positive enrichment direction
  annotate("text", nrow(topMF)+.4, y = min(topMF$NES)/3, label = sup_lab, col = "grey10", size = 3, family = "IBMPlexSans") #add annotation for the negative enrichment direction

```


```{r, echo = FALSE, eval = TRUE, error = TRUE}
DT::datatable(df.MF %>% dplyr::select(-leading_edge, -core_enrichment), extensions = 'Buttons',
                options = list(order = list(list(7 , 'asc')),
                               "dom" = 'Blfrtip',
                               buttons = c('copy', 'csv', 'excel')),
                caption = 'Significant Proteins') %>%
    DT::formatRound("enrichmentScore", digits=3) %>%
    DT::formatRound("NES", digits=3) %>%
    DT::formatSignif("pvalue", digits=5) %>%
    DT::formatSignif("p.adjust", digits=5) %>%
    DT::formatSignif("qvalue", digits=5)

```

### GO.CC
[Gene Ontology Consortium](http://geneontology.org/) knowledgebase is the world’s largest source of information on the functions of genes. Here the the locations relative to cellular structures in which a gene product performs a function are assessed.

```{r, echo = FALSE, fig.height = 7, fig.width = 12, message = FALSE, warning = FALSE, error = TRUE, eval = TRUE}

#GO term Molecular Function
gseCC <- gseGO(geneList = gene_list, #gene_list contains genes and their log2FC values, which are used for ranking the genes in GSEA
             ont = "CC", #specifies that the cellular component ontology should be used for the analysis
             keyType = "SYMBOL", #Gene symbols as input
             pvalueCutoff = p.GSEA, #p-value threshold for significant enrichment
             pAdjustMethod = "BH", #Benjamini-Hochberg correction for multiple testing
             verbose = FALSE, #omit message printing
             seed = TRUE, #consider random seed for reproducibility
             OrgDb = organism_GO, #specifies the organism
             eps = 1e-20) #a small number to prevent underflow when calculating p-values


df.CC <- gseCC@result #extract results as data.frame
rownames(df.CC) <- c() #remove rownames

#generate a dataframe with top 10 positive and negative enrichments, selected by normalized enrichment score (NES)
topCC <- full_join((df.CC %>% filter(NES >= 0) %>%
                      slice_max(order_by = NES, n = 10)), (df.CC %>% filter(NES <= 0) %>% slice_min(order_by = NES, n = 10)))

#generate a lollipop style plot
ggplot(topCC, aes(x = reorder(Description, NES), y = NES, color = p.adjust)) + #define the plot aesthetics, reorder the x-axis by NES and color by adjusted p-value
  geom_segment(aes(xend=Description, y=0, yend=NES), color = "grey", size = 2) + #add segments from y=0 to the NES value for each term, colored grey
  geom_point(size = 4) + #add points at the end of the segments, size 4
  coord_flip() + #flip the coordinates to make it horizontal
  scale_x_discrete(labels=function(x) str_wrap(x, width=60)) + #wrap long x-axis labels to a width of 60 characters
  theme(strip.text.x = element_text(size = 8)) + #adjust the size of the facet labels
  labs(x = "", y = "Normalized enrichemnt score (NES)", subtitle = "Top 10 positive and negative enrichments selected by normalized enrichment score", title = "GO:Cellular Component") + #add axis labels and title
  annotate("text", nrow(topCC)+.4, y = max(topCC$NES)/3, label = act_lab, col = "grey10", size = 3, family = "IBMPlexSans") + #add annotation for the positive enrichment direction
  annotate("text", nrow(topCC)+.4, y = min(topCC$NES)/3, label = sup_lab, col = "grey10", size = 3, family = "IBMPlexSans") #add annotation for the negative enrichment direction
```


```{r, echo = FALSE, eval = TRUE, error = TRUE}
roundcols <- c("enrichmentScore", "NES", "pvalue", "p.adjust", "q.value")

DT::datatable(df.CC %>% dplyr::select(-leading_edge, -core_enrichment), extensions = 'Buttons',
                options = list(order = list(list(7 , 'asc')),
                               "dom" = 'Blfrtip',
                               buttons = c('copy', 'csv', 'excel')),
                caption = 'Significant Proteins') %>%
    DT::formatRound("enrichmentScore", digits=3) %>%
    DT::formatRound("NES", digits=3) %>%
    DT::formatSignif("pvalue", digits=5) %>%
    DT::formatSignif("p.adjust", digits=5) %>%
    DT::formatSignif("qvalue", digits=5)

```
